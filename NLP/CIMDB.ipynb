{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIMDB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgqQimoS6dR7"
      },
      "source": [
        "# C'est la deuxième partie du projet : construire un classifieur (CIMDB) qui permet de deviner le IMDB rating du film à partir d’un dialogue dans le film.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NmI0fO99BMJ"
      },
      "source": [
        "# **1)Importez les bibliothèques:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQCgCEJZ3A90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "3f67cca2-8280-4b61-8357-3aacbf650dee"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer, one_hot\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding , Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,Bidirectional,SpatialDropout1D,GlobalMaxPooling1D\n",
        "from tensorflow.python.keras import Sequential\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ucKqpQ89VNN"
      },
      "source": [
        "# **2) Load Data:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYszjQU8_1eO"
      },
      "source": [
        "Le fichier movie_titles_metadata.txt contient des informations sur chaque film , on a besoin du 'IMDB rating' le rate de chaque film"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8erw9J6uXfVg"
      },
      "source": [
        "f1 = open('/content/gdrive/My Drive/movie_titles_metadata.txt','rb')\n",
        "\n",
        "L=[]\n",
        "for l in f1 :\n",
        "  L.append(l)\n",
        "  \n",
        "Metadata=[]\n",
        "for l in L:\n",
        "    ch=str(l)\n",
        "    gn=[]\n",
        "    A=[]\n",
        "    a=ch.split(\" +++$+++ \")\n",
        "    \n",
        "    a[3]=round(float(a[3]))\n",
        "    A.append(a[3])\n",
        "\n",
        "    \n",
        "    Metadata.append(A[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSuNcHDaXzeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80fbfdb9-f555-4819-c3f5-0fde4a3ba955"
      },
      "source": [
        "len(Metadata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j17ZCN6SQmS7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a80c5928-9057-47aa-93be-4450e566d165"
      },
      "source": [
        "Metadata[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHaU-XSmQtiT"
      },
      "source": [
        "Pour une représentation matricielle binaire du rate (catégorique):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7en57xM4YHcB"
      },
      "source": [
        "labels = to_categorical(Metadata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4WzAwTSRc4F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "096c039c-e90b-4640-d987-1fd0e6934135"
      },
      "source": [
        "labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pMnkXZABC0k"
      },
      "source": [
        "Ce deuxième fichier contient les texts des charactères"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bGeNhhL2Myh"
      },
      "source": [
        "\n",
        "f2 = open('/content/gdrive/My Drive/movie_lines.txt','rb')\n",
        "\n",
        "L2=[]\n",
        "for l in f2 :\n",
        "  L2.append(l)\n",
        "\n",
        "line=[]\n",
        "for l in L2:\n",
        "    ch=str(l)\n",
        "    gn=[]\n",
        "    a=ch.split(\" +++$+++ \")\n",
        "    if len(a)!=5:\n",
        "      continue\n",
        "    else:\n",
        "\n",
        "        a[0]=a[0][2:] \n",
        "        a[4]=a[4][:-3]  \n",
        "    \n",
        "    line.append(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AADc28TF2Ngj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "9417a23e-4964-499a-f2dc-c456c02346e1"
      },
      "source": [
        "movie_lines=pd.DataFrame(line,columns = [ 'lineId','charId','movieId','char_Name','line'])\n",
        "movie_lines.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lineId</th>\n",
              "      <th>charId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>char_Name</th>\n",
              "      <th>line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L1045</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>They do not!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L1044</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>They do to!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L985</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>I hope so.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L984</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>She okay?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L925</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>Let's go.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>L924</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>Wow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>L872</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>L871</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>L870</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>I\\'m kidding.  You know how sometimes you just...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>L869</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>Like my fear of wearing pastels?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  lineId charId  ... char_Name                                               line\n",
              "0  L1045     u0  ...    BIANCA                                       They do not!\n",
              "1  L1044     u2  ...   CAMERON                                        They do to!\n",
              "2   L985     u0  ...    BIANCA                                         I hope so.\n",
              "3   L984     u2  ...   CAMERON                                          She okay?\n",
              "4   L925     u0  ...    BIANCA                                          Let's go.\n",
              "5   L924     u2  ...   CAMERON                                                Wow\n",
              "6   L872     u0  ...    BIANCA     Okay -- you're gonna need to learn how to lie.\n",
              "7   L871     u2  ...   CAMERON                                                 No\n",
              "8   L870     u0  ...    BIANCA  I\\'m kidding.  You know how sometimes you just...\n",
              "9   L869     u0  ...    BIANCA                   Like my fear of wearing pastels?\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5ncrpyv95xD"
      },
      "source": [
        "# **3)Clean Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkuuXUCk2Wrv"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = text.strip(' ')\n",
        "    return text\n",
        "# function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
        "    return ' '.join(no_stopword_text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccV0_OThGbvc"
      },
      "source": [
        "movie_lines['line']=movie_lines['line'].apply(lambda x:clean_text(x))\n",
        "movie_lines['line']=movie_lines['line'].apply(lambda x:remove_stopwords(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpAm7fyRGl2x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "035bf56d-f89d-4666-99fe-a3f8eccff3f6"
      },
      "source": [
        "movie_lines.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lineId</th>\n",
              "      <th>charId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>char_Name</th>\n",
              "      <th>line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L1045</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L1044</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L985</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>hope</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L984</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>okay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L925</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>let go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>L924</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>wow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>L872</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>okay gonna need learn lie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>L871</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>L870</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>kidding know sometimes become persona know quit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>L869</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>like fear wearing pastels</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  lineId charId  ... char_Name                                             line\n",
              "0  L1045     u0  ...    BIANCA                                                 \n",
              "1  L1044     u2  ...   CAMERON                                                 \n",
              "2   L985     u0  ...    BIANCA                                             hope\n",
              "3   L984     u2  ...   CAMERON                                             okay\n",
              "4   L925     u0  ...    BIANCA                                           let go\n",
              "5   L924     u2  ...   CAMERON                                              wow\n",
              "6   L872     u0  ...    BIANCA                        okay gonna need learn lie\n",
              "7   L871     u2  ...   CAMERON                                                 \n",
              "8   L870     u0  ...    BIANCA  kidding know sometimes become persona know quit\n",
              "9   L869     u0  ...    BIANCA                        like fear wearing pastels\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0_dyuAkGrj2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "03f0679c-c5da-41a9-89e1-d1b75d691f1b"
      },
      "source": [
        "list(movie_lines[movie_lines.movieId=='m602'].line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oh wish woman would screwed woman loved think way',\n",
              " 'mean officially woman',\n",
              " 'well',\n",
              " 'would stop',\n",
              " 'said hate darcy oh boy men stupider true',\n",
              " 'darcy since']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQO_nKQO_Nzz"
      },
      "source": [
        "movie_diag=[]\n",
        "i=''\n",
        "word_nbr=[]\n",
        "for movie in movie_lines.movieId:\n",
        "\n",
        "  if movie==i:\n",
        "    continue\n",
        "  diag=''\n",
        "  for d in (movie_lines[movie_lines.movieId==movie].line):\n",
        "    diag=diag+d\n",
        "  movie_diag.append(diag)\n",
        "  word_nbr.append(len(diag))\n",
        "  i=movie"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8PxrsjgG6kn"
      },
      "source": [
        "df=pd.DataFrame(data=movie_diag,columns=['lines'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U6GZY18HF45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c0b8af0d-dc5e-4f96-bb16-84d03187a78b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hopeokaylet gowowokay gonna need learn liekidd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>far say also like smell sea around smells like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>officers killer duty arrestkill someone famous...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trying get hopecontinuedsorry dr smyslov reall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great greatput air tires even sell gas needcha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               lines\n",
              "0  hopeokaylet gowowokay gonna need learn liekidd...\n",
              "1  far say also like smell sea around smells like...\n",
              "2  officers killer duty arrestkill someone famous...\n",
              "3  trying get hopecontinuedsorry dr smyslov reall...\n",
              "4  great greatput air tires even sell gas needcha..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rww_iK2wHHFz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a75148b-3ef1-400e-844e-fc6b6042e8f5"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(617, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqj5jQUMHJXK"
      },
      "source": [
        "df['nbr']=[len(l.split())for l in df.lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8tF7hNOISZv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "57fe0552-abd8-414f-feb2-06ae1f32a402"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lines</th>\n",
              "      <th>nbr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hopeokaylet gowowokay gonna need learn liekidd...</td>\n",
              "      <td>1857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>far say also like smell sea around smells like...</td>\n",
              "      <td>891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>officers killer duty arrestkill someone famous...</td>\n",
              "      <td>2460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trying get hopecontinuedsorry dr smyslov reall...</td>\n",
              "      <td>1143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great greatput air tires even sell gas needcha...</td>\n",
              "      <td>2519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               lines   nbr\n",
              "0  hopeokaylet gowowokay gonna need learn liekidd...  1857\n",
              "1  far say also like smell sea around smells like...   891\n",
              "2  officers killer duty arrestkill someone famous...  2460\n",
              "3  trying get hopecontinuedsorry dr smyslov reall...  1143\n",
              "4  great greatput air tires even sell gas needcha...  2519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f06ANtl2JaWs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a500364c-e96b-47a7-c75d-2dcc1490df05"
      },
      "source": [
        "movie_diag[66]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'would find kathywowuh see signature hang note see addendum checkingsigned sponsoring officergotwickwire thomas dane see findokayrank favor pull transfer orderlieutensay nameadministration ensign blondellwould guess hold coffee klatches three us get together one time guys think kind uprisingmean manyfriend friends knowwoman sawaccused wishknow single reason father navy old time recruiting poster den showed girl trying sailor uniform saying gee wish man would join navy maybe 10 years old first saw even felt wrong made mad think month gone thought poster gee wish manwomenask somethin lieutenant come mean kinda curiousheartake away san clemente island half guys quit come back supposed hell halfproblem lieutenantthank ensignb q south side take starboard tack doorset good plates lunch office follow details jumpingcoursesecurity hell talkin base secureuh v p security arrangements generally take time senatorjordan dear treatingstanding right officeawright girl doin anywayprerogative senatorwell seein thing let handle r p point forward want press matters coordinated via office god damned gonna watch hayes pull flowers ass take credit one president shade midnight mahogany cuz comin dangerously close lookin like ronald reagantruly mouthin senior member senate arms committee mean give points style nothin smartsnothing unless suggesting infringe civil liberties would happily trim little fat constitutiongot reporters toadsquat iowa calling office askin know g jane thingsenator stand public highway telephoto lensescommander habit letting photographers traipse around base snappin fill supposed discreet test casesbasically asked could unring bellsir saywell go head lieutenant way christ nothin like 0 200 call commander chief get bowels movinwould discretion end rightsuresir tomorrow command would inquiry still go forwardsee neil dismissedsir please way without dragging everyone mudfind distasteful lieutenant desk shoulders going inquiry quick definitely pretty preparesaying friendssir someone suggesting lesbian wrongknow delicate way say lieutenant try claims made engaged fraternization sex variety specifically seen leaving apartment another female officer time manner suggest conduct unbecomingpermission evaporate neilpermission leave sirlunch good idea oh let sure invite sociologist case want fucking bridge game afterwardssir want know nothing articlemakin friends press lieutenantsee sirget everything want neil let see want gonna getget fair shotgood nightwould dream sirhappen wash wo contend bitchin hairy chested female senator please note identify one particularacross board sirstraightrules everyone sirwell least talking language one standardshape bother goddamn rotten stenchsirsirresent lieutenant politician using base test tube grand social experiment resent sensitivity training mandatory men day care center build officer lounge used ob gyn keep staff someone keep track personal pap smears lieutenant resent perfume however subtle may competing aroma fine three dollar fifty nine cent cigar happily put instant phallic nature happens offend goddamn fragile sensibilitiesthink resented start sirbarge curse base commander regard bonafide brain fart resent people fart inside homepardonbrain fartafford civility sir supposed fit guys got set outsider even make rules still lose always flag file yeah made mean really issue goddamn petticoat wear around basecivil complainingdouble standard separate quarters deferential treatment pulled chair nearly served high tea first time metoh reallysir started day cameright lieutenant give name specifics x file action first thing morning nametake longpardon hour sir told come immediately felt mistreated waylike everyone else lieutenant suspect would making statements making statements would take leavesir want know make statement want make men look foolish care completing training getting operational experience like everyone else suspectsay dismissednone time sirchange sex lieutenant separate beds separate heads specific medical needs inform infirmary classmate superior acts harassing otherwise unbecoming manner please inform immediately deal immediately questionsreally problemworry collar eyes going askbarber next stop sir would regulation soonerthank sir expect certain amount painstill coming terms exact protocol integrating spec recon training may always smooth trying make painless possiblefine sirwould care beverage teathank siryes course please seat lieutenantwestentering scannewberry get photo southproblem sirfine sirmotherachristah c monsirawneil air gonna crap soon get knowgonna pry em paddlesfuckbanditos east perimeter 150 yards shit parthey ai call manblanks lemmeai gonna shootsmokeshit thinkwhite house announced sponsoring legislation would one stroke void remaining elements 1948 combat exclusion lawsmade e r e training got call morninghearyescongress pentagon share lot plumbing never know whose leakthink overplayedact surprisedwhite house boys want private meetingaside moment struck tenor ill spirit report degrading remarks aviators innuendo performance unrelated situations even reference sexual activity weekend prior seven years committee never seen downed aviator treated like never deeply disturbed report mr hayes bodes women military confirmation wellcommission concluded aviator question failed execute proper approach carrierwould like think next secretary navy would prepared anything mr hayesreally prepared kind depth reviewyes see signature right twice size everyone else conclusion pilot error hmmone member investigating commissionnavy conclusion regarding crash f 14 aboard aircraft carrier female aviator happens familiar report conclusion rightmadam senator internal document u navy must seriously question whetherlark reportwell old dame without much time left pardon jump right discontinue blood type deeply concerned navy seemingly incontrovertible attitude toward women military case pointhardly case senatorwhoa whoa whoa land based maritime specialties gimme second de euphemizelast years brought many advances interests women naval service particularly land based maritime specialties navy instituted special sensitivity courses eyewell spoke mr hayes morning told deal test cases happy oblige play politics little darlin would way past bedtimeknow wonder secnav would think spokethink offersuredirect communication since whole thing began quite verifiablepromise wickwire fast ticketpromised fast ticket jordan always meant make good come work always use hard charger teamwanted choice chance prove skills workreality send far many men war need compound problem women honestly tell wanted life squat pissing third world junglerhetoric gets headlines reality gets troublejordan expect fully understand sometimes gained fight victorynever going let women serve combat always safety net thoughtsaying going happen president set turn third rail issue choose ever campaign fry six ways sunday sending daughters young mothers war quite possibly bringing back body bagssaying women life valuable man women death hurts familyface roper harris gallop come backknowlight bandwagon fire knows know american families prepared put daughters harm waypresident jumping bandwagonask senator asking front camerasprobably askchangedwickwire help eyes inside make sure getting fair shot least intentabsolutelyset set see failjordan might lunch tomorrow much want talk scarcelynominated spec recon three days nominatedsounds familiarknowlieutenant thomas wickwirejordan always hoped would get together though gearing child care votegonna visiting woman america cup team weeks gambler would say dennis conner days numbered san diego thought would take quick promenade baseuhhmmm maybe ask see personcomplainfollow yes dear right pick large litter success would mean lot jumpingwould one womanyes dearuh questionoffice fill help expedite look forward meeting proper time jumpingcaptain dwyer technicallytest case neil works work could well change navy official policy women combat actually official non policy immediate superiorknow sir beggin pardon senator understand involves combat trainingcaliforniacoronadohigh school pentathlete rotc scholarship graduated honors top marks basic training happens constituent home state virginia oh things one extra votethank um may ask regardingeveryone talk says top drawer silk stockings insideg jane one told last week huhthink important sir decide going since apparent issue going away quietlyhell president trying steal dehaven thundermatter picks woman going last one week commando training course caresuggest startwould go special reconnaissance every bit tough 60 percent drop rate among menpicks women pick programs sealsspotted chief pri one slip air coming tank something team showssix clock marking markingflea cool cortez newman take minis hit water go goclose get el teefuck basher basher ground crew six requesting emergency extraction stand prc fixreally wanna captured el tee heard bad thingshey okay fleaworkwell flea appreciate respect showed need want kind respect anyway gonna hurt us okayreally nothing actual brain sizereally f lee montgomery gets whittled flea shortmontgomery call fleawanted csirneilflea neil break linecome montgomeryfeel guy pecker ai tight enough want nuts buttsokaytwo one markmake wall withoutuse neil gotta go five four threethink probably would know rightoughtta reportcourse gonna stay everyone realizes bullshit equal rights thing real lives gonna lost maybe mine maybewomen ridin barebackofficer higher standardtrainee like others coming hardpay like baby sitter mean gonna onebroke dozen training rules back lost countthink would raped captured think threat rape would used leverage mengetboat five wickwire cozad vinyl intagliata ayers wise lieutenant wickwire senior officer follow orders deathevery class surprises pyro one differentmiller thought guy made depleted uranium really expect losecheck watch pyro seems fasttimemaybe place speculate private thoughts think chief knew way world come gonecoincidencechief granted early retirement 17 hundred yesterday 18 hundred gone navylooking earlierbelieve earned saving man life saudi arabia wanted clear pointnavy crossfemalesautomatic five second deduction slips wire called gender norming neil standard procedure females physical training courses last yearstry tell try neil go regulationtry anyway sirdoin fine neilthank sir like fineyes jordan wait matter longguy speaklook like would completely reach maybe could call favors get stationed norfolk instead coronado ways dealing things mean people inclinedstaring three years operational duty faceyeahwould sure like knowcrap spec recon get another shot without dispensation someone flag country got sea daddy somewherewickwire thomas dane second run coronado correct stashed appropriation liaison office whateverwickwire said dry docked washington stints coronadowashingtonwell pardon else could leveraged class officer like c mon jordan keep head gameknow carelike maybe baby sitting problem child navysounds like amazing coincidenceinstructors typically pull three year assignments guy one year year sound rightjohn james urgayle chiefwell crawl die jordan give five minutes good headworktired fighting back wanted come home safe river forget rest world okaysomeone screwed like left unanswered charges hanging head gonna fight backdone royce let goc mon jordan headworkchief maybe even turrentine cshortage suspectsalmost like someone put okaymaybe though seem like getting satisfaction almost like say class officerclass officer wickwire think trying get even striking backwanted honest chance could get could staysure join crowdjordan watch assstill make mind huh gotta go roycewant jordan meanwell let warm going though everybody fucks fucks head makes want finish expect back crying arms time soon okaytrying warn caseknow royce got enough heat without turning jetsbig symbols make big targets jordan think someone gunningtellingwalk two blocks washington without hearing g jane place whether wanted feminists sizing postersaw articleknow talkingwell pentagon scene nights ago got fresh stuff may hostile camp think someone may taking steps ensure crash burnfeel like men women men hey would expectbadhard makinghard find time sleep royce much less keep phone lifetrying five days give messagesthank royce shaping like tough call go make goddamn easy really thank muchjordanknow right said thought knowsounded lame soon came mouth trying honest okay three years long time ask predict feel jordan know eitherguy speakfeel like option paper rest life jordan maybe let happenwai wait happens works four months training three years operational dutytry keep door open wash makesorry days try thing ship coronado happensball breaker sometimes especially nightget dick back everythingwell guess even neednothingdumpneed operational duty really advance need combat training go operational yet combat training limits people tits topped intel forget glass ceiling beating head big brass ceilinghaze grey underwayroyce age started time sitting upperdecks still bullpen tell navywell doin shit hot inteltake either feetspec recon guys world class warriors want jordanlike wouldeven consideringglory sirway need option paper 11 hundred today review admiral hanover breakfast tea aroundintel glory lieutenant matter subtlehate part sweating sidelinesprobably hear back cnn firstthank sir hear back pentagongood headwork lieutenantfour minutes neutral waters sirexpect extraction team ride sub bare back correct neilquick hit technique used capone rigged getaway car running boards handles guys jump take ride check files dprk 57 doped contingency plan seal team infiltrates picks package links recovery sub waste time opening closing hatches grab periscope hang neutral watersblank faces neilunless whiskey runhalfway round world problem get teamnorth korean beaches best protected heavily monitored world civilian population propagandized acts early warning system extraction team small silent would go seals delta force problem want hold conventional sub shore target practice polkanalyst east china neil analyzechances recoverysignals received sparingly pattern leads us conclude downed aviator trying conserve batteriesknow using beacon decoydue 22 minutes sir watcha gotgotta situation stuck trafficlieutenant neilinsane got proofsorry neil class officer obligation report violationsokay well thought would askgoing place make salad pasta know nothing specialsure sureuh knowthanks lying class officer wick would weird hook besidesthink look beautifulgo likemaybe head mcp others drink four wanna comefirst big night liberty date pathetic wickwireokay ex girlfriend know remembersorry meanlet keep talkin wick keep talkinlast timewould make last time wick would get partneilgot anybody wickfirstmarriedshit gotta go get brother said worth worth training worth divorce worth anythinggood storynah dead ass asleep every guard chest left one marlboro cigarette little calling card say would could come back time wantedkill emone time rekkie libyan coastline like right bombed khadaffi past tense crew nighttime infil maps big artillery placements stuff turns around get hell gone water five libyan guards armed nutsgot good one wicksittin behind desk washington made sense somehow blame big brother spec recon stories used tellreally came backintagliata chasing breakfast found tracks well shitwick got crewknow apartment sizethanks wickhey way gutkind surpriseknow let try especially agemade week 10 last timeknowmade clear anyway stay ballsy first week hell levels e r e training anyway hell halfwhose ordersmade clear came harassment equals career suicide say anything good say much face anywaywell feel much betterafraidgrab oar find way weight gonna need cortez help flea take one two full minis follow leadmaybe half evengot two full mini tanks three minutes cool much airsmokecoollookin lookin32 feet six inchesmighta civilianfiring give away position hostiles area smartknowpart traininggonna give maple twist dumb gotta exactlyaskinguys huhshut sir concentratingneilshow us chiefgot15 sirsay many mickschief sir rescue team wo 15 minutes air situationmanaged activate elb radio base let know fix oh make sure send helo winch door blocked reefokay neil impressed others trygood see sirwell trying figure stupid unlucky gluttonous new alloy threethink oughtta practice know expectsure like menknow would raped captured even thinkglad agreethink go easy women neilknow compromised firing would given away positionone got five good men thrown bamboo cage wear bars made call got whole crewthink liarcrew said lyingrightothers already told neil wanted shoot would let went soft another womenyes mean dependswould shot manled us right threatdeemed threatshoot woman neilright worthless womb tell island world get away shit would get arrested anywhere else world take another scan little joy boy outside navy seal gonna happen huhafraidcage neil right rightgreen eggs ham going get anywhere might well put cagehungry favorite food try getdick jane spotbrothers sistersdadsimple question lieutenant reason answer father namecommissioned one month earlier makes senior officer remember bad crews bad leadersmccool rank j gengland went stress fracture puts charge lieutenantalso seems like problem men attitude sir maybe sniffing around shower room insteadfemales combat situations impact unit cohesion men fight better without women around historical factcould pulled 210 pound man clear lieutenantsee man tries rescue another man hero tries rescue woman gone softpulling 210 pound man burning barrack saudi arabiasir someone mentioned received navy cross may ask gotseems men could get used sight women blown open viscera hanging tree limbs israeli men would linger wounded females often detriment mission often endangering lives use women anymorepermission get dressed sireducate pyrochief sir understandheard movesay sirshut hole slutnikmaybe call coast guardflea keep eyes spot mark mark cortez hell waitingsuppose partcortez see dig tools without losing rest gear try wrench thingwonder happenedmovesure wants shootright fire evade maneuvers drop everything weapons prc radio gonna high speed low drag way link site readynorthclearlisten sex ape stay want roommate classmate got two options move ring end filewould get outtadesk take oneaw lookit lookit bringin tampax c mon got nothin roomsfunny c sayshey hey hey possibility stay sleep right nextanybody usin drawersnew roommatewell shit think comin likeai even workin wronggo shit plan neilai workin rightmind trying eatsomebody throw tent circuslive kill pointfuckeddarth vader reads poetryfuckedget brain picking old cia spook needed control outcome test case would man place makes everything controllablesomeone base moleokay work end think california things might handledeven tough talk every day still talk every day know meantake file still openchrist want see take fall thinksai little soldier girl sloggin way commando school implications go way beyondknow seemspresident would put little piss shoeswomensecond think leak story g jane gives dehaven symbol taps biggest constituencyfirst female presidentwhite house jordan wins dehaven wins spades well said man president fears ai manhmm let aim higherpossibly spite dehavensabotage born economics would first hayes really going start watch public failurenavy made clear want pull missiles subs make room women heads gonna cost make fleet trident co edcongress cuts military bleeds pentagon big place let narrow sightse ringers full integration gonna cost services billions worst possible time congress already swinging axeright stands gain jordan flames big waysorry thought knew knewknew usthought two file closedneil jordansubject'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBkce-lN-JXF"
      },
      "source": [
        "# **3) GLOVE :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIcJn8x2Cbmb"
      },
      "source": [
        "L'étape de préparation des données:\n",
        "\n",
        "Keras fournit une classe Tokenizer qui peut être adaptée aux données d'apprentissage, peut convertir le texte en séquences de manière cohérente en appelant la méthode textes_to_sequences () sur la classe Tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiXgup39mFDE"
      },
      "source": [
        "max_features =np.max(df.nbr) # how many unique words to use (i.e num rows in embedding vector)\n",
        "X=df['lines']\n",
        "# prepare tokenizer\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X))\n",
        "# integer encode lines\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "X = pad_sequences(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsNPLUjOFlav"
      },
      "source": [
        "Ensuite, on importe le fichier GloVe word embedding au tant que dictionnaire .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcR7klDjYaR-"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open(\"/content/gdrive/My Drive/glove.6B.100d.txt\")\n",
        "#f = open('glove.6B.300d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEPqGb_UGU3O"
      },
      "source": [
        "\n",
        "Ensuite, On crée une matrice d'une embedding pour chaque mot du dataset. On peut le faire en énumérant tous les mots uniques dans le Tokenizer.word_index et en localisant le vecteur de poids d'embedding à partir de GloVe embedding.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpGPmIpnYxe9"
      },
      "source": [
        "vocabulary_size=16078\n",
        "\n",
        "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBZf3gyuHhKG"
      },
      "source": [
        "On peut maintenant construire les modèles ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-HzLcatW5Ds"
      },
      "source": [
        "train_X, test_X, train_y , test_y = train_test_split(X,labels ,test_size=0.2, random_state=20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJSPyWfsOyEs"
      },
      "source": [
        "# **4) Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO_NR9ot_qpI"
      },
      "source": [
        " **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IfNQXsdR1z1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9645dfc6-375c-4417-f710-bef786e263b5"
      },
      "source": [
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(vocabulary_size,100,weights = [embedding_matrix],input_length=train_X.shape[1],trainable = False))\n",
        "model_lstm.add(SpatialDropout1D(0.2))\n",
        "model_lstm.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model_lstm.add(Dense(52,activation = 'relu'))\n",
        "model_lstm.add(Dense(10, activation='softmax'))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 100\n",
        "\n",
        "history = model_lstm.fit(train_X, train_y, epochs=epochs, batch_size=batch_size,validation_split=0.1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 80s 16s/step - loss: 2.2165 - accuracy: 0.1806 - val_loss: 2.0098 - val_accuracy: 0.3200\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 79s 16s/step - loss: 1.8856 - accuracy: 0.2889 - val_loss: 1.7625 - val_accuracy: 0.2400\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 79s 16s/step - loss: 1.6855 - accuracy: 0.3318 - val_loss: 1.7054 - val_accuracy: 0.2800\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 79s 16s/step - loss: 1.6074 - accuracy: 0.3251 - val_loss: 1.6777 - val_accuracy: 0.2400\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 79s 16s/step - loss: 1.6052 - accuracy: 0.3589 - val_loss: 1.6724 - val_accuracy: 0.2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXRbGkY8Y1ax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e12ae7c-b845-473e-9f17-cf8322dca790"
      },
      "source": [
        "pred_lstm= model_lstm.predict(test_X , verbose=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 5s 1s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b1f90LhP-iI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "687be992-544f-4a4c-8481-9738e29a6413"
      },
      "source": [
        "pred_lstm[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00647645, 0.00271519, 0.00332619, 0.00126094, 0.0344288 ,\n",
              "       0.07641193, 0.25730637, 0.2819725 , 0.3216231 , 0.01447863],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8sM5X9FNHO2"
      },
      "source": [
        "Cet prédiction est faite sur la base d'une valeur seuil de 0,5, ce qui signifie que les probabilités supérieures ou égales à 0,5 ont été converties en 1 et les autres en 0.\n",
        "On va modifier cette valeur seuil à 0.2 pour améliorer le score du modèle:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsMnJb_ftPBw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "2ee685ea-161a-44db-cc4d-31aa1ce14480"
      },
      "source": [
        "# predict probabilities\n",
        "y_pred_prob = model_lstm.predict_proba(test_X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-595dc334d90d>:1: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use `model.predict()` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXZCOrDZtar2"
      },
      "source": [
        "t = 0.2 # threshold value\n",
        "y_pred_new = (y_pred_prob >= t).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTs0TppLtd_r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9876cbc3-85c0-44b3-e3b4-3ca819d381ad"
      },
      "source": [
        "f1_score(test_y, y_pred_new, average=\"micro\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4210526315789474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ57qbmE_wAS"
      },
      "source": [
        " **CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhnAUWMfZDWa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fba5cdf5-e51b-4f3c-f3cd-b7d23e284bfc"
      },
      "source": [
        "model_cnn = Sequential()\n",
        "model_cnn.add(Embedding(vocabulary_size,100,weights = [embedding_matrix],input_length=train_X.shape[1],trainable = False))\n",
        "model_cnn.add(Conv1D(100, 5, activation='relu'))\n",
        "model_cnn.add(GlobalMaxPooling1D())\n",
        "model_cnn.add(Dense(55, activation='relu'))\n",
        "model_cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 90\n",
        "\n",
        "history = model_cnn.fit(train_X, train_y, epochs=epochs, batch_size=batch_size,validation_split=0.1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.0113 - accuracy: 0.2144 - val_loss: 1.7382 - val_accuracy: 0.3400\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 14s 3s/step - loss: 1.6098 - accuracy: 0.3702 - val_loss: 1.6503 - val_accuracy: 0.2800\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 14s 3s/step - loss: 1.4776 - accuracy: 0.4989 - val_loss: 1.6306 - val_accuracy: 0.4000\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 14s 3s/step - loss: 1.3954 - accuracy: 0.5734 - val_loss: 1.6193 - val_accuracy: 0.2800\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 14s 3s/step - loss: 1.3121 - accuracy: 0.6817 - val_loss: 1.6027 - val_accuracy: 0.3400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0EUGcBKQOrZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29a302cc-0e93-4f19-9fbe-eb0f2d181d05"
      },
      "source": [
        "pred= model_cnn.predict(test_X , verbose=1)\n",
        "# predict probabilities\n",
        "y_pred_prob = model_cnn.predict_proba(test_X)\n",
        "t = 0.2 # threshold value\n",
        "y_pred_new = (y_pred_prob >= t).astype(int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 303ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSXtzWm1ldG7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76a6eb66-15d8-42a4-c7c8-d8d388adddfa"
      },
      "source": [
        "f1_score(test_y, y_pred_new, average=\"micro\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4201312910284464"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB9_ul3X-ngc"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yX5S31cMg6C"
      },
      "source": [
        "emb = Sequential()\n",
        "emb.add(Embedding(vocabulary_size,100,weights = [embedding_matrix],input_length=train_X.shape[1],trainable = False))\n",
        "emb.add(GlobalMaxPooling1D())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-N7WAbqMiIH"
      },
      "source": [
        "Train_X_emb=emb.predict(train_X)\n",
        "Test_X_emb=emb.predict(test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYaBULvuMmvh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "805cbe65-7522-4cda-f767-5f2042f4c451"
      },
      "source": [
        "SVM = OneVsRestClassifier(SVC(probability=True))\n",
        "SVM.fit(Train_X_emb,train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 0 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 1 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                                  class_weight=None, coef0=0.0,\n",
              "                                  decision_function_shape='ovr', degree=3,\n",
              "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                                  probability=True, random_state=None,\n",
              "                                  shrinking=True, tol=0.001, verbose=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eccoQtBuMp7N"
      },
      "source": [
        "predictions_SVM = SVM.predict(Test_X_emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kVO0J3VMsgc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71f0da9f-5e43-4668-baf2-771618df8125"
      },
      "source": [
        "y_pred_prob = SVM.predict_proba(Test_X_emb)\n",
        "t = 0.2 # threshold value\n",
        "y_pred_new = (y_pred_prob >= t).astype(int)\n",
        "\n",
        "f1_score(test_y, y_pred_new, average=\"micro\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4059196617336152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKYlsdbcULgA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}